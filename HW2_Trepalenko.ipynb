{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2. Часть 1\n",
    "\n",
    "##### Трепаленко Александра, бкл182\n",
    "*Для работы используется небольшой рассказ, потому что моему ноутбуку требуется очень много времени даже для его обработки.*\n",
    "### Обработка книги с помощью mystem\n",
    "Импортируем необходимые модули, читаем файл с книгой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycodestyle in c:\\programdata\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: flake8 in c:\\programdata\\anaconda3\\lib\\site-packages (3.7.8)\n",
      "Requirement already satisfied: pycodestyle_magic in c:\\programdata\\anaconda3\\lib\\site-packages (0.4)\n",
      "Requirement already satisfied: entrypoints<0.4.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flake8) (0.3)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flake8) (0.6.1)\n",
      "Requirement already satisfied: pyflakes<2.2.0,>=2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flake8) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install pycodestyle flake8 pycodestyle_magic\n",
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on\n",
    "import json\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "\n",
    "m = Mystem()\n",
    "with open('smorodin.txt', encoding='utf-8-sig') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Время обработки и запись в файл\n",
    "С помощью метода .analyze() распарсиваем текст. Результат записываем в файл формата .json. Время работы замеряем при помощи %time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 13s\n"
     ]
    }
   ],
   "source": [
    "%time ana = m.analyze(text)\n",
    "with open('mystem.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(ana, f, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка книги через pymorphy\n",
    "Импортируем новые модули. Чистим текст от пунктуации и создаем пустой список для слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "PUNCT = list(\"\"\".,…;:!?@#$%^&*№()_—=+|[]{}/\\\"<>`~±§«»\"\"\") + ['- ', ' -', ' - ']\n",
    "for sign in PUNCT:\n",
    "    text = text.replace(sign, '')\n",
    "words_from_text = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Время обработки и запись в файл\n",
    "При помощи word_tokenize и .parse() сначала токенизируем, а потом разбираем словоформы. В созданный ранее список в видео кортежа записываем лемму и часть речи. Записываем результат в файл в формате .json. Время работы опять же замеряется при помощи %time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 169 ms\n"
     ]
    }
   ],
   "source": [
    "%time words = word_tokenize(text)\n",
    "for word in words:\n",
    "    ana = morph.parse(word)\n",
    "    new_word = ana[0]\n",
    "    a = (new_word.word, new_word.tag.POS, new_word.normal_form)\n",
    "    words_from_text.append(a)\n",
    "with open('pymorphy.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(words_from_text, f, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вопросы\n",
    "\n",
    "### Какую долю слов составляет каждая часть речи?\n",
    "Импоритруем модуль Counter. Создаем списки для всех частей речи и лемм. Берем каждый элемент из списка всех слов текста и отправляем его составляющие в соответствующие списки. Считаем, сколько рах встречается каждая часть речи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "all_POS = []\n",
    "all_lemmas = []\n",
    "for element in words_from_text:\n",
    "    all_POS.append(element[1])\n",
    "    all_lemmas.append(element[2])\n",
    "c = Counter(all_POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Часть речи - процент:\n",
      "NOUN - 27.5%\n",
      "ADJF - 9.705882352941176%\n",
      "ADJS - 2.6715686274509802%\n",
      "VERB - 14.215686274509803%\n",
      "PREP - 9.044117647058824%\n",
      "NPRO - 9.485294117647058%\n",
      "PRTF - 0.46568627450980393%\n",
      "ADVB - 5.857843137254902%\n",
      "CONJ - 10.073529411764707%\n",
      "PRCL - 5.857843137254902%\n",
      "INTJ - 0.29411764705882354%\n",
      "PRTS - 0.6617647058823529%\n",
      "GRND - 0.5392156862745098%\n",
      "INFN - 1.7156862745098038%\n",
      "PRED - 0.6372549019607843%\n",
      "NUMR - 1.0049019607843137%\n",
      "COMP - 0.2696078431372549%\n"
     ]
    }
   ],
   "source": [
    "print('Часть речи - процент:')\n",
    "for POS, number in c.items():\n",
    "    freq = str(number*100/len(all_POS))\n",
    "    print(str(POS) + ' - ' + freq + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Топ-20 глаголов и наречий\n",
    "Создаем списки для глаголов и наречий. Для каждого элемента списка слов проверяем, является ли он глаголом или наречием, и отправляем в соответствующий список. При помощи метода most_common оставляем самые частотные варианты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = []\n",
    "adverbs = []\n",
    "for element in words_from_text:\n",
    "    if element[1] == 'VERB':\n",
    "        verbs.append(element[2])\n",
    "    if element[1] == 'ADVB':\n",
    "        adverbs.append(element[2])\n",
    "c_verbs = Counter(verbs)\n",
    "c_adverbs = Counter(adverbs)\n",
    "common_verbs = c_verbs.most_common(20)\n",
    "common_adverbs = c_adverbs.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-20 глаголов\n",
      "Глагол - количество:\n",
      "быть - 86\n",
      "сказать - 20\n",
      "мочь - 13\n",
      "видеть - 12\n",
      "любить - 9\n",
      "заказывать - 9\n",
      "произнести - 7\n",
      "есть - 7\n",
      "хотеть - 7\n",
      "проговорить - 6\n",
      "спросить - 6\n",
      "жить - 6\n",
      "думать - 6\n",
      "ответить - 6\n",
      "помнить - 5\n",
      "понимать - 5\n",
      "принести - 5\n",
      "ужинать - 5\n",
      "ходить - 5\n",
      "находить - 5\n",
      "\n",
      "Топ-20 наречий\n",
      "Наречие - количество:\n",
      "весьма - 12\n",
      "много - 10\n",
      "там - 8\n",
      "здесь - 8\n",
      "всегда - 7\n",
      "очень - 7\n",
      "назад - 6\n",
      "вполне - 5\n",
      "слишком - 5\n",
      "уже - 5\n",
      "совершенно - 5\n",
      "никогда - 4\n",
      "где - 4\n",
      "сюда - 4\n",
      "естественно - 4\n",
      "хорошо - 4\n",
      "снова - 4\n",
      "действительно - 4\n",
      "утром - 4\n",
      "вовсе - 4\n"
     ]
    }
   ],
   "source": [
    "print('Топ-20 глаголов\\nГлагол - количество:')\n",
    "for verb in common_verbs:\n",
    "    print(verb[0], '-', verb[1])\n",
    "print('\\nТоп-20 наречий\\nНаречие - количество:')\n",
    "for adverb in common_adverbs:\n",
    "    print(adverb[0], '-', adverb[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Топ-25 биграмм и триграмм\n",
    "При помощи ngrams собираем список сначала биграмм, затем триграмм. Для каждого используем Counter и оставляем 25 наиболее частотных вариантов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "\n",
    "bigrams = list(ngrams(all_lemmas, 2))\n",
    "c_b = Counter(bigrams)\n",
    "common_bigrams = c_b.most_common(25)\n",
    "trigrams = list(ngrams(all_lemmas, 3))\n",
    "c_t = Counter(trigrams)\n",
    "common_trigrams = c_t.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Биграмма - количество:\n",
      "эркюля пуарый - 20\n",
      "он быть - 15\n",
      "чёрный смородина - 14\n",
      "что он - 12\n",
      "мистер бонингтон - 11\n",
      "это быть - 11\n",
      "мистер гаскон - 11\n",
      "я не - 10\n",
      "в ресторан - 9\n",
      "он не - 8\n",
      "и он - 8\n",
      "у он - 8\n",
      "миссис хилый - 8\n",
      "тот же - 7\n",
      "в тот - 6\n",
      "пирог с - 6\n",
      "не быть - 6\n",
      "генри гаскон - 6\n",
      "доктор мак-эндрю - 6\n",
      "джордж рамзь - 6\n",
      "в семь - 6\n",
      "гэлант эндивор - 5\n",
      "с он - 5\n",
      "что я - 5\n",
      "совершенно верно - 5\n",
      "\n",
      "Триграмма - количество\n",
      "у он быть - 7\n",
      "в ресторан гэлант - 4\n",
      "ресторан гэлант эндивор - 4\n",
      "вторник и четверг - 4\n",
      "пудинг с почка - 4\n",
      "с почка и - 4\n",
      "и пирог с - 4\n",
      "пирог с чёрный - 4\n",
      "с чёрный смородина - 4\n",
      "в карман халат - 4\n",
      "в семь тридцать - 4\n",
      "год тот назад - 4\n",
      "к тот же - 3\n",
      "сказать эркюля пуарый - 3\n",
      "сказать мистер бонингтон - 3\n",
      "и чёрный смородина - 3\n",
      "почка и пирог - 3\n",
      "не замечать что - 3\n",
      "замечать что заказывать - 3\n",
      "он не быть - 3\n",
      "по это повод - 3\n",
      "на кингз роуд - 3\n",
      "в тот же - 3\n",
      "на кингстон хилла - 3\n",
      "смерть мистер гаскон - 3\n"
     ]
    }
   ],
   "source": [
    "print('Биграмма - количество:')\n",
    "for bigram in common_bigrams:\n",
    "    print(*bigram[0], '-', bigram[1])\n",
    "print('\\nТриграмма - количество')\n",
    "for trigram in common_trigrams:\n",
    "    print(*trigram[0], '-', trigram[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
